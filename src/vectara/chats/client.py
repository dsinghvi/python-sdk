# This file was auto-generated by Fern from our API Definition.

import json
import typing
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.jsonable_encoder import jsonable_encoder
from ..core.pydantic_utilities import pydantic_v1
from ..core.request_options import RequestOptions
from ..errors.bad_request_error import BadRequestError
from ..errors.forbidden_error import ForbiddenError
from ..errors.not_found_error import NotFoundError
from ..types.bad_request_error_body import BadRequestErrorBody
from ..types.chat import Chat
from ..types.chat_full_response import ChatFullResponse
from ..types.chat_parameters import ChatParameters
from ..types.error import Error
from ..types.generation_parameters import GenerationParameters
from ..types.list_chat_turns_response import ListChatTurnsResponse
from ..types.list_chats_response import ListChatsResponse
from ..types.not_found_error_body import NotFoundErrorBody
from ..types.search_corpora_parameters import SearchCorporaParameters
from ..types.turn import Turn

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ChatsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        limit: typing.Optional[int] = None,
        page_key: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListChatsResponse:
        """
        Retrieve a list of previous chats in the Vectara account.

        Parameters
        ----------
        limit : typing.Optional[int]
            The maximum number of results to return in the list.

        page_key : typing.Optional[str]
            Used to the retrieve the next page of chats after the limit has been reached.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListChatsResponse
            List of chats.

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.list()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v2/chats", method="GET", params={"limit": limit, "page_key": page_key}, request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(ListChatsResponse, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        query: str,
        search: SearchCorporaParameters,
        generation: typing.Optional[GenerationParameters] = OMIT,
        chat: typing.Optional[ChatParameters] = OMIT,
        stream_response: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[ChatFullResponse]:
        """
        Create a chat while specifying the default retrieval parameters used by the prompt.

        Parameters
        ----------
        query : str
            The chat message or question.

        search : SearchCorporaParameters

        generation : typing.Optional[GenerationParameters]

        chat : typing.Optional[ChatParameters]

        stream_response : typing.Optional[bool]
            Indicates whether the response should be streamed or not.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.Iterator[ChatFullResponse]
            A response to a chat request.

        Examples
        --------
        from vectara import (
            ChatParameters,
            CitationParameters,
            ContextConfiguration,
            GenerationParameters,
            KeyedSearchCorpus,
            ModelParameters,
            SearchCorporaParameters,
            SearchReranker_CustomerReranker,
        )
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        response = client.chats.create(
            query="string",
            search=SearchCorporaParameters(
                corpora=[KeyedSearchCorpus()],
                offset=1,
                limit=1,
                context_configuration=ContextConfiguration(),
                reranker=SearchReranker_CustomerReranker(),
            ),
            generation=GenerationParameters(
                prompt_name="string",
                max_used_search_results=1,
                prompt_text="string",
                max_response_characters=1,
                response_language="auto",
                model_parameters=ModelParameters(
                    max_tokens=1,
                    temperature=1.1,
                    frequency_penalty=1.1,
                    presence_penalty=1.1,
                ),
                citations=CitationParameters(),
                enable_factual_consistency_score=True,
            ),
            chat=ChatParameters(),
            stream_response=True,
        )
        for chunk in response:
            yield chunk
        """
        with self._client_wrapper.httpx_client.stream(
            "v2/chats",
            method="POST",
            json={
                "query": query,
                "search": search,
                "generation": generation,
                "chat": chat,
                "stream_response": stream_response,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            if 200 <= _response.status_code < 300:
                for _text in _response.iter_lines():
                    if len(_text) == 0:
                        continue
                    yield pydantic_v1.parse_obj_as(ChatFullResponse, json.loads(_text))  # type: ignore
                return
            _response.read()
            if _response.status_code == 400:
                raise BadRequestError(pydantic_v1.parse_obj_as(BadRequestErrorBody, _response.json()))  # type: ignore
            if _response.status_code == 403:
                raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
            if _response.status_code == 404:
                raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> Chat:
        """
        Get a chat summary to view what started the chat, but not subsequent turns.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Chat
            A chat.

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.get(
            chat_id="chat_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Chat, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete a chat and any turns it contains permanently.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.delete(
            chat_id="chat_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}", method="DELETE", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_turns(
        self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ListChatTurnsResponse:
        """
        List all turns in a chat to see all message and response pairs that make up the dialog.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListChatTurnsResponse
            List of turns.

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.list_turns(
            chat_id="chat_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(ListChatTurnsResponse, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_turns(
        self,
        chat_id: str,
        *,
        query: str,
        search: SearchCorporaParameters,
        generation: typing.Optional[GenerationParameters] = OMIT,
        chat: typing.Optional[ChatParameters] = OMIT,
        stream_response: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[ChatFullResponse]:
        """
        Create a new turn in the chat. Each conversation has a series of `turn` objects, which are the sequence of message and response pairs tha make up the dialog.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        query : str
            The chat message or question.

        search : SearchCorporaParameters

        generation : typing.Optional[GenerationParameters]

        chat : typing.Optional[ChatParameters]

        stream_response : typing.Optional[bool]
            Indicates whether the response should be streamed or not.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.Iterator[ChatFullResponse]
            A response to a chat request.

        Examples
        --------
        from vectara import (
            ChatParameters,
            CitationParameters,
            ContextConfiguration,
            GenerationParameters,
            KeyedSearchCorpus,
            ModelParameters,
            SearchCorporaParameters,
            SearchReranker_CustomerReranker,
        )
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        response = client.chats.create_turns(
            chat_id="string",
            query="string",
            search=SearchCorporaParameters(
                corpora=[KeyedSearchCorpus()],
                offset=1,
                limit=1,
                context_configuration=ContextConfiguration(),
                reranker=SearchReranker_CustomerReranker(),
            ),
            generation=GenerationParameters(
                prompt_name="string",
                max_used_search_results=1,
                prompt_text="string",
                max_response_characters=1,
                response_language="auto",
                model_parameters=ModelParameters(
                    max_tokens=1,
                    temperature=1.1,
                    frequency_penalty=1.1,
                    presence_penalty=1.1,
                ),
                citations=CitationParameters(),
                enable_factual_consistency_score=True,
            ),
            chat=ChatParameters(),
            stream_response=True,
        )
        for chunk in response:
            yield chunk
        """
        with self._client_wrapper.httpx_client.stream(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns",
            method="POST",
            json={
                "query": query,
                "search": search,
                "generation": generation,
                "chat": chat,
                "stream_response": stream_response,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            if 200 <= _response.status_code < 300:
                for _text in _response.iter_lines():
                    if len(_text) == 0:
                        continue
                    yield pydantic_v1.parse_obj_as(ChatFullResponse, json.loads(_text))  # type: ignore
                return
            _response.read()
            if _response.status_code == 400:
                raise BadRequestError(pydantic_v1.parse_obj_as(BadRequestErrorBody, _response.json()))  # type: ignore
            if _response.status_code == 403:
                raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
            if _response.status_code == 404:
                raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_turn(self, chat_id: str, turn_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> Turn:
        """
        Get a specific turn from a chat, which is a message and response pair from the conversation.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Turn
            The turn.

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.get_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="GET",
            request_options=request_options,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Turn, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_turn(
        self, chat_id: str, turn_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a turn from a chat. This will delete all subsequent turns in the chat.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.delete_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="DELETE",
            request_options=request_options,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_turn(
        self,
        chat_id: str,
        turn_id: str,
        *,
        enabled: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Turn:
        """
        Update a turn; used to disable or enable a chat.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        enabled : typing.Optional[bool]
            Indicates whether to disable a turn. It will disable this turn and all subsequent turns.
            Enabling a turn is not implemented.


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Turn
            Succcessfully modified the turn.

        Examples
        --------
        from vectara.client import Vectara

        client = Vectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        client.chats.update_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="PATCH",
            json={"enabled": enabled},
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Turn, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncChatsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        limit: typing.Optional[int] = None,
        page_key: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListChatsResponse:
        """
        Retrieve a list of previous chats in the Vectara account.

        Parameters
        ----------
        limit : typing.Optional[int]
            The maximum number of results to return in the list.

        page_key : typing.Optional[str]
            Used to the retrieve the next page of chats after the limit has been reached.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListChatsResponse
            List of chats.

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.list()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v2/chats", method="GET", params={"limit": limit, "page_key": page_key}, request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(ListChatsResponse, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        query: str,
        search: SearchCorporaParameters,
        generation: typing.Optional[GenerationParameters] = OMIT,
        chat: typing.Optional[ChatParameters] = OMIT,
        stream_response: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[ChatFullResponse]:
        """
        Create a chat while specifying the default retrieval parameters used by the prompt.

        Parameters
        ----------
        query : str
            The chat message or question.

        search : SearchCorporaParameters

        generation : typing.Optional[GenerationParameters]

        chat : typing.Optional[ChatParameters]

        stream_response : typing.Optional[bool]
            Indicates whether the response should be streamed or not.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.AsyncIterator[ChatFullResponse]
            A response to a chat request.

        Examples
        --------
        from vectara import (
            ChatParameters,
            CitationParameters,
            ContextConfiguration,
            GenerationParameters,
            KeyedSearchCorpus,
            ModelParameters,
            SearchCorporaParameters,
            SearchReranker_CustomerReranker,
        )
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        response = await client.chats.create(
            query="string",
            search=SearchCorporaParameters(
                corpora=[KeyedSearchCorpus()],
                offset=1,
                limit=1,
                context_configuration=ContextConfiguration(),
                reranker=SearchReranker_CustomerReranker(),
            ),
            generation=GenerationParameters(
                prompt_name="string",
                max_used_search_results=1,
                prompt_text="string",
                max_response_characters=1,
                response_language="auto",
                model_parameters=ModelParameters(
                    max_tokens=1,
                    temperature=1.1,
                    frequency_penalty=1.1,
                    presence_penalty=1.1,
                ),
                citations=CitationParameters(),
                enable_factual_consistency_score=True,
            ),
            chat=ChatParameters(),
            stream_response=True,
        )
        async for chunk in response:
            yield chunk
        """
        async with self._client_wrapper.httpx_client.stream(
            "v2/chats",
            method="POST",
            json={
                "query": query,
                "search": search,
                "generation": generation,
                "chat": chat,
                "stream_response": stream_response,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            if 200 <= _response.status_code < 300:
                async for _text in _response.aiter_lines():
                    if len(_text) == 0:
                        continue
                    yield pydantic_v1.parse_obj_as(ChatFullResponse, json.loads(_text))  # type: ignore
                return
            await _response.aread()
            if _response.status_code == 400:
                raise BadRequestError(pydantic_v1.parse_obj_as(BadRequestErrorBody, _response.json()))  # type: ignore
            if _response.status_code == 403:
                raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
            if _response.status_code == 404:
                raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> Chat:
        """
        Get a chat summary to view what started the chat, but not subsequent turns.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Chat
            A chat.

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.get(
            chat_id="chat_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Chat, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete a chat and any turns it contains permanently.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.delete(
            chat_id="chat_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}", method="DELETE", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_turns(
        self, chat_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ListChatTurnsResponse:
        """
        List all turns in a chat to see all message and response pairs that make up the dialog.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListChatTurnsResponse
            List of turns.

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.list_turns(
            chat_id="chat_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(ListChatTurnsResponse, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_turns(
        self,
        chat_id: str,
        *,
        query: str,
        search: SearchCorporaParameters,
        generation: typing.Optional[GenerationParameters] = OMIT,
        chat: typing.Optional[ChatParameters] = OMIT,
        stream_response: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[ChatFullResponse]:
        """
        Create a new turn in the chat. Each conversation has a series of `turn` objects, which are the sequence of message and response pairs tha make up the dialog.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        query : str
            The chat message or question.

        search : SearchCorporaParameters

        generation : typing.Optional[GenerationParameters]

        chat : typing.Optional[ChatParameters]

        stream_response : typing.Optional[bool]
            Indicates whether the response should be streamed or not.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.AsyncIterator[ChatFullResponse]
            A response to a chat request.

        Examples
        --------
        from vectara import (
            ChatParameters,
            CitationParameters,
            ContextConfiguration,
            GenerationParameters,
            KeyedSearchCorpus,
            ModelParameters,
            SearchCorporaParameters,
            SearchReranker_CustomerReranker,
        )
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        response = await client.chats.create_turns(
            chat_id="string",
            query="string",
            search=SearchCorporaParameters(
                corpora=[KeyedSearchCorpus()],
                offset=1,
                limit=1,
                context_configuration=ContextConfiguration(),
                reranker=SearchReranker_CustomerReranker(),
            ),
            generation=GenerationParameters(
                prompt_name="string",
                max_used_search_results=1,
                prompt_text="string",
                max_response_characters=1,
                response_language="auto",
                model_parameters=ModelParameters(
                    max_tokens=1,
                    temperature=1.1,
                    frequency_penalty=1.1,
                    presence_penalty=1.1,
                ),
                citations=CitationParameters(),
                enable_factual_consistency_score=True,
            ),
            chat=ChatParameters(),
            stream_response=True,
        )
        async for chunk in response:
            yield chunk
        """
        async with self._client_wrapper.httpx_client.stream(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns",
            method="POST",
            json={
                "query": query,
                "search": search,
                "generation": generation,
                "chat": chat,
                "stream_response": stream_response,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            if 200 <= _response.status_code < 300:
                async for _text in _response.aiter_lines():
                    if len(_text) == 0:
                        continue
                    yield pydantic_v1.parse_obj_as(ChatFullResponse, json.loads(_text))  # type: ignore
                return
            await _response.aread()
            if _response.status_code == 400:
                raise BadRequestError(pydantic_v1.parse_obj_as(BadRequestErrorBody, _response.json()))  # type: ignore
            if _response.status_code == 403:
                raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
            if _response.status_code == 404:
                raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_turn(
        self, chat_id: str, turn_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> Turn:
        """
        Get a specific turn from a chat, which is a message and response pair from the conversation.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Turn
            The turn.

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.get_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="GET",
            request_options=request_options,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Turn, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_turn(
        self, chat_id: str, turn_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a turn from a chat. This will delete all subsequent turns in the chat.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.delete_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="DELETE",
            request_options=request_options,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_turn(
        self,
        chat_id: str,
        turn_id: str,
        *,
        enabled: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Turn:
        """
        Update a turn; used to disable or enable a chat.

        Parameters
        ----------
        chat_id : str
            The ID of the chat.

        turn_id : str
            The ID of the turn.

        enabled : typing.Optional[bool]
            Indicates whether to disable a turn. It will disable this turn and all subsequent turns.
            Enabling a turn is not implemented.


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Turn
            Succcessfully modified the turn.

        Examples
        --------
        from vectara.client import AsyncVectara

        client = AsyncVectara(
            api_key="YOUR_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.chats.update_turn(
            chat_id="chat_id",
            turn_id="turn_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v2/chats/{jsonable_encoder(chat_id)}/turns/{jsonable_encoder(turn_id)}",
            method="PATCH",
            json={"enabled": enabled},
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(Turn, _response.json())  # type: ignore
        if _response.status_code == 403:
            raise ForbiddenError(pydantic_v1.parse_obj_as(Error, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic_v1.parse_obj_as(NotFoundErrorBody, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
